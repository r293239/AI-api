<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Learning System - Persistent Memory Demo</title>
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        header {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-bottom: 1px solid rgba(255, 255, 255, 0.2);
            padding: 1rem 0;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .header-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .logo {
            font-size: 2rem;
            font-weight: bold;
            color: white;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .nav-links {
            display: flex;
            gap: 2rem;
        }

        .nav-links a {
            color: white;
            text-decoration: none;
            padding: 0.5rem 1rem;
            border-radius: 25px;
            transition: background 0.3s ease;
        }

        .nav-links a:hover {
            background: rgba(255, 255, 255, 0.2);
        }

        .hero {
            text-align: center;
            padding: 4rem 0;
            color: white;
        }

        .hero h1 {
            font-size: 3.5rem;
            margin-bottom: 1rem;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            animation: fadeInUp 1s ease-out;
        }

        .hero p {
            font-size: 1.3rem;
            margin-bottom: 2rem;
            opacity: 0.9;
            animation: fadeInUp 1s ease-out 0.2s both;
        }

        .status-indicator {
            display: inline-block;
            padding: 0.5rem 1rem;
            border-radius: 25px;
            font-weight: bold;
            margin-bottom: 2rem;
            animation: fadeInUp 1s ease-out 0.3s both;
        }

        .status-loading {
            background: rgba(255, 193, 7, 0.2);
            color: #ffc107;
            border: 2px solid #ffc107;
        }

        .status-ready {
            background: rgba(40, 167, 69, 0.2);
            color: #28a745;
            border: 2px solid #28a745;
        }

        .status-error {
            background: rgba(220, 53, 69, 0.2);
            color: #dc3545;
            border: 2px solid #dc3545;
        }

        .memory-indicator {
            display: inline-block;
            padding: 0.3rem 0.8rem;
            border-radius: 15px;
            font-size: 0.9rem;
            margin-left: 1rem;
            background: rgba(138, 43, 226, 0.2);
            color: #8a2be2;
            border: 2px solid #8a2be2;
        }

        .cta-button {
            display: inline-block;
            background: linear-gradient(45deg, #ff6b6b, #ee5a24);
            color: white;
            padding: 1rem 2rem;
            border-radius: 50px;
            text-decoration: none;
            font-weight: bold;
            font-size: 1.1rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            animation: fadeInUp 1s ease-out 0.4s both;
            cursor: pointer;
            border: none;
        }

        .cta-button:hover:not(:disabled) {
            transform: translateY(-3px);
            box-shadow: 0 15px 40px rgba(0,0,0,0.4);
        }

        .cta-button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        .demo-section {
            background: white;
            padding: 4rem 0;
            margin-top: 2rem;
        }

        .demo-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 3rem;
            align-items: start;
        }

        .demo-controls {
            background: #f8f9fa;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }

        .demo-output {
            background: #2d3748;
            color: #e2e8f0;
            padding: 2rem;
            border-radius: 15px;
            font-family: 'Courier New', monospace;
            height: 600px;
            overflow-y: auto;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }

        .form-group {
            margin-bottom: 1.5rem;
        }

        .form-group label {
            display: block;
            margin-bottom: 0.5rem;
            font-weight: bold;
            color: #333;
        }

        .form-group select,
        .form-group input {
            width: 100%;
            padding: 0.8rem;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            font-size: 1rem;
        }

        .form-group select:focus,
        .form-group input:focus {
            outline: none;
            border-color: #667eea;
        }

        .demo-button {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            padding: 1rem 2rem;
            border: none;
            border-radius: 25px;
            font-size: 1rem;
            font-weight: bold;
            cursor: pointer;
            transition: transform 0.3s ease;
            width: 100%;
            margin-bottom: 1rem;
        }

        .demo-button:hover:not(:disabled) {
            transform: translateY(-2px);
        }

        .demo-button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        .memory-button {
            background: linear-gradient(45deg, #8a2be2, #9932cc);
            font-size: 0.9rem;
            padding: 0.8rem 1.5rem;
        }

        .danger-button {
            background: linear-gradient(45deg, #dc3545, #c82333);
        }

        .progress-bar {
            width: 100%;
            height: 20px;
            background: #e2e8f0;
            border-radius: 10px;
            overflow: hidden;
            margin-bottom: 1rem;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(45deg, #667eea, #764ba2);
            width: 0%;
            transition: width 0.3s ease;
        }

        .memory-section {
            background: #f8f9fa;
            border: 2px solid #8a2be2;
            border-radius: 10px;
            padding: 1.5rem;
            margin-bottom: 2rem;
        }

        .memory-section h4 {
            color: #8a2be2;
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .memory-stats {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 1rem;
            margin-bottom: 1rem;
            font-size: 0.9rem;
        }

        .memory-stat {
            background: rgba(138, 43, 226, 0.1);
            padding: 0.5rem;
            border-radius: 5px;
            text-align: center;
        }

        .memory-controls {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 0.5rem;
        }

        .features {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 4rem 0;
        }

        .features h2 {
            text-align: center;
            font-size: 2.5rem;
            margin-bottom: 3rem;
        }

        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
        }

        .feature-card {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 2rem;
            border-radius: 20px;
            border: 1px solid rgba(255, 255, 255, 0.2);
            transition: transform 0.3s ease;
        }

        .feature-card:hover {
            transform: translateY(-5px);
        }

        .feature-card h3 {
            font-size: 1.5rem;
            margin-bottom: 1rem;
        }

        .visualization {
            background: white;
            border: 2px solid #e2e8f0;
            border-radius: 10px;
            padding: 1rem;
            margin-top: 1rem;
        }

        .grid-display {
            display: inline-block;
            border: 2px solid #333;
            padding: 5px;
            background: #f9f9f9;
        }

        .grid-row {
            display: flex;
        }

        .grid-cell {
            width: 35px;
            height: 35px;
            border: 1px solid #ccc;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 14px;
        }

        .agent { background: #4ade80; color: white; }
        .goal { background: #f59e0b; color: white; }
        .wall { background: #6b7280; color: white; }
        .empty { background: #f9fafb; }

        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        .file-input {
            display: none;
        }

        .file-label {
            background: linear-gradient(45deg, #28a745, #20c997);
            color: white;
            padding: 0.8rem 1.5rem;
            border-radius: 25px;
            cursor: pointer;
            font-size: 0.9rem;
            font-weight: bold;
            display: inline-block;
            transition: transform 0.3s ease;
        }

        .file-label:hover {
            transform: translateY(-2px);
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .metrics {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 8px;
            margin-top: 1rem;
            font-size: 0.9rem;
        }

        .metric-row {
            display: flex;
            justify-content: space-between;
            margin-bottom: 0.5rem;
        }

        footer {
            background: #2d3748;
            color: white;
            text-align: center;
            padding: 2rem 0;
        }

        @media (max-width: 768px) {
            .hero h1 { font-size: 2.5rem; }
            .demo-container { grid-template-columns: 1fr; }
            .nav-links { display: none; }
            .memory-controls { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <div class="header-content">
                <div class="logo">üß† Persistent AI System</div>
                <nav class="nav-links">
                    <a href="#demo">Live Demo</a>
                    <a href="#features">Features</a>
                    <a href="#memory">Memory</a>
                </nav>
            </div>
        </div>
    </header>

    <section class="hero">
        <div class="container">
            <h1>Forever-Learning AI System</h1>
            <p>Real reinforcement learning with persistent memory - AI that never forgets!</p>
            <div class="status-indicator" id="python-status">
                <span class="loading"></span> Loading Python Environment...
            </div>
            <div class="memory-indicator" id="memory-status">
                üíæ Memory: Initializing...
            </div>
            <button class="cta-button" id="scroll-demo" onclick="scrollToDemo()" disabled>Try Persistent Demo</button>
        </div>
    </section>

    <section class="demo-section" id="demo">
        <div class="container">
            <h2 style="text-align: center; margin-bottom: 3rem; font-size: 2.5rem;">Persistent AI Demo</h2>
            <div class="demo-container">
                <div class="demo-controls">
                    <div class="memory-section">
                        <h4>üß† AI Memory System</h4>
                        <div class="memory-stats">
                            <div class="memory-stat">
                                <strong id="stored-tasks">0</strong><br>
                                <small>Stored Tasks</small>
                            </div>
                            <div class="memory-stat">
                                <strong id="total-episodes">0</strong><br>
                                <small>Total Episodes</small>
                            </div>
                            <div class="memory-stat">
                                <strong id="memory-size">0 KB</strong><br>
                                <small>Memory Used</small>
                            </div>
                            <div class="memory-stat">
                                <strong id="last-saved">Never</strong><br>
                                <small>Last Saved</small>
                            </div>
                        </div>
                        <div class="memory-controls">
                            <button class="demo-button memory-button" onclick="saveMemory()">üíæ Save Progress</button>
                            <button class="demo-button memory-button" onclick="loadMemory()">üìÅ Load Progress</button>
                            <button class="demo-button memory-button" onclick="exportMemory()">üì§ Export Data</button>
                            <input type="file" id="import-file" class="file-input" accept=".json" onchange="importMemory(event)">
                            <label for="import-file" class="file-label">üì• Import Data</label>
                        </div>
                    </div>

                    <h3 style="margin-bottom: 2rem;">Real AI Training Controls</h3>
                    
                    <div class="form-group">
                        <label for="task-type">Select Task Type</label>
                        <select id="task-type">
                            <option value="navigation">Grid Navigation</option>
                            <option value="sorting">Array Sorting</option>
                        </select>
                    </div>

                    <div class="form-group" id="nav-config">
                        <label for="grid-size">Grid Size</label>
                        <select id="grid-size">
                            <option value="4">4x4 Grid</option>
                            <option value="5">5x5 Grid</option>
                            <option value="6">6x6 Grid</option>
                        </select>
                    </div>

                    <div class="form-group">
                        <label for="episodes">Training Episodes</label>
                        <select id="episodes">
                            <option value="100">100 episodes (fast)</option>
                            <option value="300">300 episodes (medium)</option>
                            <option value="500">500 episodes (thorough)</option>
                        </select>
                    </div>

                    <button class="demo-button" id="start-training" onclick="startTraining()" disabled>
                        üöÄ Start Persistent Training
                    </button>

                    <div class="progress-bar" style="display: none;" id="progress-container">
                        <div class="progress-fill" id="progress-fill"></div>
                    </div>
                    <div id="progress-text" style="text-align: center; margin-bottom: 1rem; font-weight: bold;"></div>

                    <button class="demo-button" id="test-ai" onclick="testAI()" disabled>
                        üéØ Test Persistent AI
                    </button>

                    <button class="demo-button" id="show-progress" onclick="showProgress()" disabled>
                        üìä Show Learning History
                    </button>

                    <button class="demo-button" id="continue-training" onclick="continueTraining()" disabled>
                        üîÑ Continue Training
                    </button>

                    <button class="demo-button danger-button" onclick="clearMemory()">
                        üóëÔ∏è Clear All Memory
                    </button>

                    <div class="visualization" id="visualization" style="display: none;">
                        <h4>Environment Visualization</h4>
                        <div id="grid-display"></div>
                        <div class="metrics" id="metrics"></div>
                    </div>
                </div>

                <div class="demo-output" id="output">
                    <div style="color: #4ade80; font-weight: bold;">üß† Persistent AI Learning System Console</div>
                    <div style="color: #94a3b8; margin-bottom: 1rem;">AI with Forever Memory - Never loses progress!</div>
                    <div id="init-status">Initializing persistent memory system...</div>
                </div>
            </div>
        </div>
    </section>

    <section class="features" id="features">
        <div class="container">
            <h2>Persistent AI Capabilities</h2>
            <div class="feature-grid">
                <div class="feature-card">
                    <h3>üíæ Forever Memory</h3>
                    <p>AI training data persists forever in browser storage. Resume training anytime from exactly where you left off!</p>
                </div>
                <div class="feature-card">
                    <h3>üìä Learning History</h3>
                    <p>Complete training history, performance metrics, and neural network weights are automatically saved and restored.</p>
                </div>
                <div class="feature-card">
                    <h3>üîÑ Continuous Learning</h3>
                    <p>AI can continue learning indefinitely across browser sessions. Each training session builds on previous knowledge.</p>
                </div>
                <div class="feature-card">
                    <h3>üì§ Portable Knowledge</h3>
                    <p>Export and import AI knowledge as JSON files. Share trained AIs or backup your progress!</p>
                </div>
                <div class="feature-card">
                    <h3>üß† Multi-Task Memory</h3>
                    <p>Store multiple trained AIs simultaneously. Each task type maintains its own persistent learning progress.</p>
                </div>
                <div class="feature-card">
                    <h3>‚ö° Instant Resume</h3>
                    <p>No training time lost! Instantly resume from your last session with all neural network weights intact.</p>
                </div>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2025 Persistent AI Learning System. AI that truly never forgets!</p>
            <p>Powered by Pyodide WebAssembly + Browser Persistent Storage</p>
        </div>
    </footer>

    <script>
        let pyodide;
        let aiSystem;
        let currentTrainingTask = null;
        let isTraining = false;
        let memoryDB;

        // Memory management variables
        let persistentData = {
            tasks: {},
            totalEpisodes: 0,
            memorySize: 0,
            lastSaved: null
        };

        // Initialize IndexedDB for persistent storage
        async function initializeMemoryDB() {
            return new Promise((resolve, reject) => {
                const request = indexedDB.open('AILearningSystem', 1);
                
                request.onerror = () => reject(request.error);
                request.onsuccess = () => {
                    memoryDB = request.result;
                    resolve(memoryDB);
                };
                
                request.onupgradeneeded = (event) => {
                    const db = event.target.result;
                    if (!db.objectStoreNames.contains('aiData')) {
                        db.createObjectStore('aiData', { keyPath: 'id' });
                    }
                };
            });
        }

        // Save AI data to persistent storage
        async function saveToMemory(key, data) {
            if (!memoryDB) return;
            
            const transaction = memoryDB.transaction(['aiData'], 'readwrite');
            const store = transaction.objectStore('aiData');
            
            await store.put({
                id: key,
                data: data,
                timestamp: Date.now()
            });
            
            updateMemoryStats();
        }

        // Load AI data from persistent storage
        async function loadFromMemory(key) {
            if (!memoryDB) return null;
            
            const transaction = memoryDB.transaction(['aiData'], 'readonly');
            const store = transaction.objectStore('aiData');
            const request = store.get(key);
            
            return new Promise((resolve) => {
                request.onsuccess = () => {
                    resolve(request.result ? request.result.data : null);
                };
                request.onerror = () => resolve(null);
            });
        }

        // Initialize Pyodide and load the AI system with memory
        async function initializePyodide() {
            try {
                updateStatus('Initializing persistent memory...', 'loading');
                await initializeMemoryDB();
                
                updateStatus('Loading Python runtime...', 'loading');
                pyodide = await loadPyodide();
                
                updateStatus('Installing NumPy...', 'loading');
                await pyodide.loadPackage("numpy");
                
                updateStatus('Loading AI Learning System...', 'loading');
                
                // Load the complete AI learning system code with memory support
                pyodide.runPython(`
import numpy as np
import json
import pickle
from typing import List, Tuple, Optional, Dict, Any, Callable
import random
from abc import ABC, abstractmethod
import time

# [Previous AI system code here - same as before]
class Memory:
    """Experience replay memory for storing and learning from past actions"""
    
    def __init__(self, capacity: int = 10000):
        self.capacity = capacity
        self.memory = []
        self.position = 0
    
    def push(self, state, action, reward, next_state, done):
        """Store an experience"""
        if len(self.memory) < self.capacity:
            self.memory.append(None)
        
        self.memory[self.position] = (state, action, reward, next_state, done)
        self.position = (self.position + 1) % self.capacity
    
    def sample(self, batch_size: int):
        """Sample random experiences for training"""
        if len(self.memory) < batch_size:
            return random.sample(self.memory, len(self.memory))
        return random.sample(self.memory, batch_size)
    
    def __len__(self):
        return len(self.memory)

class NeuralNetwork:
    """Simple neural network for function approximation"""
    
    def __init__(self, input_size: int, hidden_sizes: List[int], output_size: int, learning_rate: float = 0.01):
        self.learning_rate = learning_rate
        self.layers = []
        
        # Build network architecture
        sizes = [input_size] + hidden_sizes + [output_size]
        for i in range(len(sizes) - 1):
            layer = {
                'weights': np.random.randn(sizes[i], sizes[i+1]) * 0.1,
                'biases': np.zeros((1, sizes[i+1])),
                'activations': None,
                'z_values': None
            }
            self.layers.append(layer)
    
    def relu(self, x):
        return np.maximum(0, x)
    
    def relu_derivative(self, x):
        return (x > 0).astype(float)
    
    def forward(self, x):
        """Forward pass through network"""
        activation = x.reshape(1, -1) if x.ndim == 1 else x
        
        for i, layer in enumerate(self.layers):
            z = np.dot(activation, layer['weights']) + layer['biases']
            layer['z_values'] = z
            
            if i < len(self.layers) - 1:  # Hidden layers use ReLU
                activation = self.relu(z)
            else:  # Output layer (linear)
                activation = z
                
            layer['activations'] = activation
        
        return activation.flatten() if activation.shape[0] == 1 else activation
    
    def backward(self, x, target):
        """Backpropagation to update weights"""
        # Forward pass first
        output = self.forward(x)
        
        # Calculate loss gradient (MSE)
        output_error = output.reshape(1, -1) - target.reshape(1, -1)
        
        # Backward pass
        for i in reversed(range(len(self.layers))):
            layer = self.layers[i]
            
            if i == len(self.layers) - 1:  # Output layer
                delta = output_error
            else:  # Hidden layers
                delta = np.dot(delta, self.layers[i+1]['weights'].T) * self.relu_derivative(layer['z_values'])
            
            # Get input to this layer
            if i == 0:
                layer_input = x.reshape(1, -1)
            else:
                layer_input = self.layers[i-1]['activations']
            
            # Update weights and biases
            layer['weights'] -= self.learning_rate * np.dot(layer_input.T, delta)
            layer['biases'] -= self.learning_rate * np.sum(delta, axis=0, keepdims=True)
    
    def copy(self):
        """Create a copy of the network"""
        new_net = NeuralNetwork(1, [], 1)  # Dummy initialization
        new_net.layers = []
        for layer in self.layers:
            new_layer = {
                'weights': layer['weights'].copy(),
                'biases': layer['biases'].copy(),
                'activations': None,
                'z_values': None
            }
            new_net.layers.append(new_layer)
        return new_net
    
    def to_dict(self):
        """Serialize network to dictionary"""
        return {
            'learning_rate': self.learning_rate,
            'layers': [{
                'weights': layer['weights'].tolist(),
                'biases': layer['biases'].tolist()
            } for layer in self.layers]
        }
    
    def from_dict(self, data):
        """Load network from dictionary"""
        self.learning_rate = data['learning_rate']
        self.layers = []
        for layer_data in data['layers']:
            layer = {
                'weights': np.array(layer_data['weights']),
                'biases': np.array(layer_data['biases']),
                'activations': None,
                'z_values': None
            }
            self.layers.append(layer)

class Environment(ABC):
    """Abstract base class for environments the AI can learn in"""
    
    @abstractmethod
    def reset(self):
        pass
    
    @abstractmethod
    def step(self, action):
        pass
    
    @abstractmethod
    def get_state_size(self):
        pass
    
    @abstractmethod
    def get_action_size(self):
        pass

class GridWorldEnvironment(Environment):
    """Grid world environment"""
    
    def __init__(self, width: int = 5, height: int = 5):
        self.width = width
        self.height = height
        self.reset()
        
        # Define rewards
        self.goal_reward = 100
        self.step_penalty = -1
        self.wall_penalty = -10
    
    def reset(self):
        """Reset to starting position"""
        self.agent_pos = [0, 0]
        self.goal_pos = [self.width-1, self.height-1]
        self.walls = [(2, 2), (2, 3), (3, 2)] if self.width >= 4 else []
        return self.get_state()
    
    def get_state(self):
        """Get current state representation"""
        state = np.zeros(self.width * self.height + 4)
        
        # One-hot encode agent position
        agent_idx = self.agent_pos[1] * self.width + self.agent_pos[0]
        state[agent_idx] = 1
        
        # Add agent and goal positions as features
        state[-4] = self.agent_pos[0] / self.width
        state[-3] = self.agent_pos[1] / self.height
        state[-2] = self.goal_pos[0] / self.width
        state[-1] = self.goal_pos[1] / self.height
        
        return state
    
    def step(self, action):
        """Take action: 0=up, 1=right, 2=down, 3=left"""
        old_pos = self.agent_pos.copy()
        
        # Apply action
        if action == 0:  # Up
            self.agent_pos[1] = max(0, self.agent_pos[1] - 1)
        elif action == 1:  # Right
            self.agent_pos[0] = min(self.width-1, self.agent_pos[0] + 1)
        elif action == 2:  # Down
            self.agent_pos[1] = min(self.height-1, self.agent_pos[1] + 1)
        elif action == 3:  # Left
            self.agent_pos[0] = max(0, self.agent_pos[0] - 1)
        
        # Check if hit wall
        if tuple(self.agent_pos) in self.walls:
            self.agent_pos = old_pos  # Bounce back
            reward = self.wall_penalty
        elif self.agent_pos == self.goal_pos:
            reward = self.goal_reward
        else:
            reward = self.step_penalty
        
        done = (self.agent_pos == self.goal_pos)
        
        return self.get_state(), reward, done, {}
    
    def get_state_size(self):
        return self.width * self.height + 4
    
    def get_action_size(self):
        return 4
    
    def render(self):
        """Visual representation of the environment"""
        grid = [['.' for _ in range(self.width)] for _ in range(self.height)]
        
        # Add walls
        for wall in self.walls:
            if 0 <= wall[0] < self.width and 0 <= wall[1] < self.height:
                grid[wall[1]][wall[0]] = '#'
        
        # Add goal
        grid[self.goal_pos[1]][self.goal_pos[0]] = 'G'
        
        # Add agent
        grid[self.agent_pos[1]][self.agent_pos[0]] = 'A'
        
        return grid

class TaskEnvironment(Environment):
    """Environment for learning specific tasks"""
    
    def __init__(self, task_type: str = "sorting"):
        self.task_type = task_type
        self.reset()
    
    def reset(self):
        if self.task_type == "sorting":
            # Generate random array to sort
            self.array = np.random.randint(1, 10, size=5)
            self.target = np.sort(self.array)
            self.current_array = self.array.copy()
            self.steps = 0
            self.max_steps = 20
        
        return self.get_state()
    
    def get_state(self):
        if self.task_type == "sorting":
            # State includes current array and target
            state = np.concatenate([
                self.current_array / 10.0,  # Normalize
                self.target / 10.0,
                [self.steps / self.max_steps]
            ])
            return state
    
    def step(self, action):
        if self.task_type == "sorting":
            # Actions: swap adjacent elements (0-3) or do nothing (4)
            if action < 4 and action < len(self.current_array) - 1:
                # Swap elements at position action and action+1
                self.current_array[action], self.current_array[action+1] = \
                    self.current_array[action+1], self.current_array[action]
            
            self.steps += 1
            
            # Calculate reward
            if np.array_equal(self.current_array, self.target):
                reward = 100  # Solved!
                done = True
            elif self.steps >= self.max_steps:
                reward = -50  # Failed
                done = True
            else:
                # Reward based on how close to sorted
                inversions = self._count_inversions()
                reward = -inversions - 1  # Small penalty for each step
                done = False
            
            return self.get_state(), reward, done, {}
    
    def _count_inversions(self):
        """Count how many pairs are out of order"""
        count = 0
        for i in range(len(self.current_array)):
            for j in range(i+1, len(self.current_array)):
                if self.current_array[i] > self.current_array[j]:
                    count += 1
        return count
    
    def get_state_size(self):
        if self.task_type == "sorting":
            return 11  # 5 current + 5 target + 1 step
    
    def get_action_size(self):
        if self.task_type == "sorting":
            return 5  # 4 swaps + 1 do nothing

class PersistentDQNAgent:
    """DQN Agent with persistent memory capabilities"""
    
    def __init__(self, state_size: int, action_size: int, learning_rate: float = 0.01):
        self.state_size = state_size
        self.action_size = action_size
        self.memory = Memory(capacity=2000)
        
        # Hyperparameters
        self.epsilon = 1.0
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.gamma = 0.95
        self.batch_size = 32
        
        # Neural networks
        self.q_network = NeuralNetwork(state_size, [64, 64], action_size, learning_rate)
        self.target_network = self.q_network.copy()
        self.update_target_frequency = 100
        self.update_counter = 0
        
        # Training stats
        self.episode_rewards = []
        self.episode_steps = []
        self.total_training_time = 0
        self.sessions = []
    
    def act(self, state, training=True):
        """Choose action using epsilon-greedy policy"""
        if training and np.random.random() <= self.epsilon:
            return np.random.choice(self.action_size)
        
        q_values = self.q_network.forward(state)
        return np.argmax(q_values)
    
    def remember(self, state, action, reward, next_state, done):
        """Store experience in memory"""
        self.memory.push(state, action, reward, next_state, done)
    
    def replay(self):
        """Train the network on a batch of experiences"""
        if len(self.memory) < self.batch_size:
            return
        
        experiences = self.memory.sample(self.batch_size)
        
        for state, action, reward, next_state, done in experiences:
            target = reward
            if not done:
                next_q_values = self.target_network.forward(next_state)
                target = reward + self.gamma * np.max(next_q_values)
            
            # Get current Q values
            current_q_values = self.q_network.forward(state)
            target_q_values = current_q_values.copy()
            target_q_values[action] = target
            
            # Train network
            self.q_network.backward(state, target_q_values)
        
        # Decay exploration
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay
        
        # Update target network periodically
        self.update_counter += 1
        if self.update_counter % self.update_target_frequency == 0:
            self.target_network = self.q_network.copy()
    
    def train(self, environment: Environment, episodes: int = 1000, verbose: bool = True):
        """Train the agent with session tracking"""
        session_start = len(self.episode_rewards)
        session_rewards = []
        
        for episode in range(episodes):
            state = environment.reset()
            total_reward = 0
            steps = 0
            
            while True:
                action = self.act(state)
                next_state, reward, done, _ = environment.step(action)
                
                self.remember(state, action, reward, next_state, done)
                state = next_state
                total_reward += reward
                steps += 1
                
                if done or steps > 1000:
                    break
            
            self.episode_rewards.append(total_reward)
            self.episode_steps.append(steps)
            session_rewards.append(total_reward)
            
            # Train on experiences
            self.replay()
            
            if verbose and episode % 50 == 0:
                avg_reward = np.mean(session_rewards[-50:]) if len(session_rewards) >= 50 else np.mean(session_rewards)
                print(f"Episode {session_start + episode}, Session Avg: {avg_reward:.2f}, Epsilon: {self.epsilon:.3f}")
        
        # Record session
        self.sessions.append({
            'start_episode': session_start,
            'episodes': episodes,
            'avg_reward': np.mean(session_rewards),
            'timestamp': time.time()
        })
    
    def test(self, environment: Environment, episodes: int = 10):
        """Test the trained agent"""
        test_rewards = []
        test_results = []
        
        for episode in range(episodes):
            state = environment.reset()
            total_reward = 0
            steps = 0
            episode_states = []
            
            while True:
                action = self.act(state, training=False)
                episode_states.append((state, action, environment.agent_pos.copy() if hasattr(environment, 'agent_pos') else None))
                state, reward, done, _ = environment.step(action)
                total_reward += reward
                steps += 1
                
                if done or steps > 50:
                    break
            
            test_rewards.append(total_reward)
            test_results.append({
                'episode': episode + 1,
                'reward': total_reward,
                'steps': steps,
                'states': episode_states
            })
        
        avg_test_reward = np.mean(test_rewards)
        return test_results, avg_test_reward
    
    def to_dict(self):
        """Serialize agent to dictionary for persistence"""
        return {
            'state_size': self.state_size,
            'action_size': self.action_size,
            'epsilon': self.epsilon,
            'epsilon_min': self.epsilon_min,
            'epsilon_decay': self.epsilon_decay,
            'gamma': self.gamma,
            'update_counter': self.update_counter,
            'q_network': self.q_network.to_dict(),
            'target_network': self.target_network.to_dict(),
            'episode_rewards': self.episode_rewards,
            'episode_steps': self.episode_steps,
            'total_training_time': self.total_training_time,
            'sessions': self.sessions
        }
    
    def from_dict(self, data):
        """Load agent from dictionary"""
        self.state_size = data['state_size']
        self.action_size = data['action_size']
        self.epsilon = data['epsilon']
        self.epsilon_min = data['epsilon_min']
        self.epsilon_decay = data['epsilon_decay']
        self.gamma = data['gamma']
        self.update_counter = data['update_counter']
        
        # Restore neural networks
        self.q_network = NeuralNetwork(self.state_size, [64, 64], self.action_size)
        self.q_network.from_dict(data['q_network'])
        self.target_network = NeuralNetwork(self.state_size, [64, 64], self.action_size)
        self.target_network.from_dict(data['target_network'])
        
        # Restore training history
        self.episode_rewards = data['episode_rewards']
        self.episode_steps = data['episode_steps']
        self.total_training_time = data.get('total_training_time', 0)
        self.sessions = data.get('sessions', [])

class PersistentLearningAI:
    """AI system with full persistent memory"""
    
    def __init__(self):
        self.agents = {}
        self.environments = {}
        self.current_task = None
        self.system_stats = {
            'total_episodes': 0,
            'total_tasks': 0,
            'creation_time': time.time()
        }
    
    def add_task(self, task_name: str, environment: Environment):
        """Add a new task for the AI to learn"""
        self.environments[task_name] = environment
        
        # Create specialized agent for this task
        state_size = environment.get_state_size()
        action_size = environment.get_action_size()
        self.agents[task_name] = PersistentDQNAgent(state_size, action_size)
        
        self.system_stats['total_tasks'] += 1
        print(f"Added persistent task '{task_name}' with state size {state_size} and {action_size} actions")
    
    def learn_task(self, task_name: str, episodes: int = 1000):
        """Train the AI on a specific task"""
        if task_name not in self.agents:
            print(f"Task '{task_name}' not found!")
            return
        
        print(f"=== Learning Task: {task_name} (Session {len(self.agents[task_name].sessions) + 1}) ===")
        agent = self.agents[task_name]
        environment = self.environments[task_name]
        
        agent.train(environment, episodes)
        self.current_task = task_name
        self.system_stats['total_episodes'] += episodes
        
        print(f"Finished learning '{task_name}'! Total episodes: {len(agent.episode_rewards)}")
        return agent
    
    def demonstrate_task(self, task_name: str, episodes: int = 3):
        """Show the AI performing a learned task"""
        if task_name not in self.agents:
            print(f"Task '{task_name}' not found!")
            return None, 0
        
        print(f"=== Demonstrating Persistent Task: {task_name} ===")
        agent = self.agents[task_name]
        environment = self.environments[task_name]
        
        return agent.test(environment, episodes)
    
    def get_learning_progress(self, task_name: str):
        """Get comprehensive learning statistics"""
        if task_name not in self.agents:
            return None
        
        agent = self.agents[task_name]
        if not agent.episode_rewards:
            return None
        
        recent_performance = np.mean(agent.episode_rewards[-100:]) if len(agent.episode_rewards) >= 100 else np.mean(agent.episode_rewards)
        
        return {
            'episodes_trained': len(agent.episode_rewards),
            'recent_avg_reward': recent_performance,
            'best_reward': max(agent.episode_rewards),
            'exploration_rate': agent.epsilon,
            'all_rewards': agent.episode_rewards.copy(),
            'sessions': agent.sessions.copy(),
            'total_sessions': len(agent.sessions),
            'avg_session_performance': np.mean([s['avg_reward'] for s in agent.sessions]) if agent.sessions else 0
        }
    
    def to_dict(self):
        """Serialize entire AI system"""
        return {
            'system_stats': self.system_stats,
            'agents': {name: agent.to_dict() for name, agent in self.agents.items()},
            'current_task': self.current_task,
            'save_timestamp': time.time()
        }
    
    def from_dict(self, data):
        """Load entire AI system from data"""
        self.system_stats = data.get('system_stats', self.system_stats)
        self.current_task = data.get('current_task')
        
        # Restore agents
        for task_name, agent_data in data.get('agents', {}).items():
            # Recreate environment based on task type
            if 'navigation' in task_name:
                # Extract grid size from agent data or use default
                grid_size = 5  # Default
                self.add_task(task_name, GridWorldEnvironment(grid_size, grid_size))
            elif 'sorting' in task_name:
                self.add_task(task_name, TaskEnvironment("sorting"))
            
            # Load agent data
            if task_name in self.agents:
                self.agents[task_name].from_dict(agent_data)

# Global persistent AI instance
global_persistent_ai = PersistentLearningAI()
print("üß† Persistent AI Learning System initialized!")
                `);

                // Load any existing persistent data
                await loadPersistentData();
                
                updateStatus('Persistent AI System ready!', 'ready');
                enableControls();
                log('üéâ Persistent AI Learning System loaded and ready!');
                log('üíæ Your AI will remember everything forever!');
                log('üîÑ Resume training from exactly where you left off.');
                
                updateMemoryStats();
                
            } catch (error) {
                console.error('Error initializing:', error);
                updateStatus('Failed to load Python environment', 'error');
                log(`‚ùå Error: ${error.message}`);
            }
        }

        async function loadPersistentData() {
            try {
                const savedData = await loadFromMemory('aiSystem');
                if (savedData) {
                    pyodide.runPython(`
import json
saved_data = json.loads('${JSON.stringify(savedData).replace(/'/g, "\\'")}')
global_persistent_ai.from_dict(saved_data)
print(f"‚úÖ Loaded persistent data: {len(saved_data.get('agents', {}))} tasks")
                    `);
                    
                    const output = pyodide.runPython(`
agents_info = []
for task_name, agent in global_persistent_ai.agents.items():
    agents_info.append(f"{task_name}: {len(agent.episode_rewards)} episodes")
"\\n   ".join(agents_info) if agents_info else "No saved tasks"
                    `);
                    
                    log('üîÑ Restored persistent AI memory:');
                    log(`   ${output}`);
                    
                    // Enable relevant buttons if we have saved data
                    if (savedData.agents && Object.keys(savedData.agents).length > 0) {
                        document.getElementById('continue-training').disabled = false;
                        document.getElementById('test-ai').disabled = false;
                        document.getElementById('show-progress').disabled = false;
                        
                        if (savedData.current_task) {
                            currentTrainingTask = savedData.current_task;
                            document.getElementById('task-type').value = 
                                savedData.current_task.includes('navigation') ? 'navigation' : 'sorting';
                        }
                    }
                }
            } catch (error) {
                console.error('Error loading persistent data:', error);
                log('‚ÑπÔ∏è No previous data found - starting fresh');
            }
        }

        async function savePersistentData() {
            try {
                const aiData = pyodide.runPython(`
import json
ai_dict = global_persistent_ai.to_dict()
json.dumps(ai_dict)
                `);
                
                const parsedData = JSON.parse(aiData);
                await saveToMemory('aiSystem', parsedData);
                
                persistentData.lastSaved = new Date().toLocaleString();
                log('üíæ AI progress saved to persistent memory');
                return true;
            } catch (error) {
                console.error('Error saving:', error);
                log(`‚ùå Save error: ${error.message}`);
                return false;
            }
        }

        async function updateMemoryStats() {
            try {
                // Get current AI stats
                const stats = pyodide.runPython(`
{
    'total_tasks': len(global_persistent_ai.agents),
    'total_episodes': sum(len(agent.episode_rewards) for agent in global_persistent_ai.agents.values()),
    'memory_size': len(str(global_persistent_ai.to_dict()))
}
                `);
                
                document.getElementById('stored-tasks').textContent = stats.get('total_tasks') || 0;
                document.getElementById('total-episodes').textContent = stats.get('total_episodes') || 0;
                document.getElementById('memory-size').textContent = `${Math.round((stats.get('memory_size') || 0) / 1024)} KB`;
                document.getElementById('last-saved').textContent = persistentData.lastSaved || 'Never';
                
                // Update memory status indicator
                const memoryStatus = document.getElementById('memory-status');
                const totalTasks = stats.get('total_tasks') || 0;
                const totalEpisodes = stats.get('total_episodes') || 0;
                
                if (totalTasks > 0) {
                    memoryStatus.textContent = `üíæ Memory: ${totalTasks} tasks, ${totalEpisodes} episodes`;
                    memoryStatus.style.background = 'rgba(40, 167, 69, 0.2)';
                    memoryStatus.style.color = '#28a745';
                    memoryStatus.style.borderColor = '#28a745';
                } else {
                    memoryStatus.textContent = 'üíæ Memory: Empty';
                }
                
            } catch (error) {
                console.error('Error updating memory stats:', error);
            }
        }

        function updateStatus(message, type) {
            const statusEl = document.getElementById('python-status');
            const scrollBtn = document.getElementById('scroll-demo');
            
            statusEl.className = `status-indicator status-${type}`;
            
            if (type === 'loading') {
                statusEl.innerHTML = `<span class="loading"></span> ${message}`;
            } else if (type === 'ready') {
                statusEl.innerHTML = `‚úÖ ${message}`;
                scrollBtn.disabled = false;
            } else if (type === 'error') {
                statusEl.innerHTML = `‚ùå ${message}`;
            }
        }

        function enableControls() {
            document.getElementById('start-training').disabled = false;
        }

        function log(message) {
            const output = document.getElementById('output');
            const timestamp = new Date().toLocaleTimeString();
            output.innerHTML += `<div style="color: #94a3b8; display: inline;">[${timestamp}]</div> ${message}<br>`;
            output.scrollTop = output.scrollHeight;
        }

        // Memory management functions
        async function saveMemory() {
            const success = await savePersistentData();
            if (success) {
                updateMemoryStats();
                log('‚úÖ Progress saved to browser memory permanently!');
            }
        }

        async function loadMemory() {
            try {
                await loadPersistentData();
                updateMemoryStats();
                log('‚úÖ Memory loaded successfully!');
            } catch (error) {
                log(`‚ùå Load error: ${error.message}`);
            }
        }

        async function exportMemory() {
            try {
                const aiData = pyodide.runPython(`
import json
ai_dict = global_persistent_ai.to_dict()
json.dumps(ai_dict, indent=2)
                `);
                
                const blob = new Blob([aiData], { type: 'application/json' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = `ai-memory-${new Date().toISOString().split('T')[0]}.json`;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
                
                log('üì§ AI memory exported successfully!');
            } catch (error) {
                log(`‚ùå Export error: ${error.message}`);
            }
        }

        async function importMemory(event) {
            const file = event.target.files[0];
            if (!file) return;
            
            try {
                const text = await file.text();
                const data = JSON.parse(text);
                
                // Validate data structure
                if (!data.agents || !data.system_stats) {
                    throw new Error('Invalid AI memory file format');
                }
                
                pyodide.runPython(`
import json
imported_data = json.loads('${text.replace(/'/g, "\\'")}')
global_persistent_ai.from_dict(imported_data)
print(f"Imported {len(imported_data.get('agents', {}))} tasks")
                `);
                
                await savePersistentData();
                updateMemoryStats();
                
                // Enable controls
                if (Object.keys(data.agents).length > 0) {
                    document.getElementById('continue-training').disabled = false;
                    document.getElementById('test-ai').disabled = false;
                    document.getElementById('show-progress').disabled = false;
                }
                
                log('üì• AI memory imported successfully!');
                log(`   Imported ${Object.keys(data.agents).length} trained tasks`);
                
            } catch (error) {
                log(`‚ùå Import error: ${error.message}`);
            }
            
            // Reset file input
            event.target.value = '';
        }

        async function clearMemory() {
            if (!confirm('‚ö†Ô∏è This will permanently delete all AI memory. Are you sure?')) {
                return;
            }
            
            try {
                // Clear IndexedDB
                if (memoryDB) {
                    const transaction = memoryDB.transaction(['aiData'], 'readwrite');
                    const store = transaction.objectStore('aiData');
                    await store.clear();
                }
                
                // Reset Python AI
                pyodide.runPython(`
global_persistent_ai = PersistentLearningAI()
print("AI memory cleared")
                `);
                
                // Reset UI state
                currentTrainingTask = null;
                persistentData.lastSaved = null;
                
                document.getElementById('continue-training').disabled = true;
                document.getElementById('test-ai').disabled = true;
                document.getElementById('show-progress').disabled = true;
                document.getElementById('visualization').style.display = 'none';
                
                updateMemoryStats();
                log('üóëÔ∏è All AI memory permanently cleared');
                
            } catch (error) {
                log(`‚ùå Clear error: ${error.message}`);
            }
        }

        async function startTraining() {
            if (isTraining) return;
            
            const taskType = document.getElementById('task-type').value;
            const episodes = parseInt(document.getElementById('episodes').value);
            const gridSize = parseInt(document.getElementById('grid-size').value);
            
            const startBtn = document.getElementById('start-training');
            startBtn.disabled = true;
            startBtn.innerHTML = '<span class="loading"></span> Training Persistent AI...';
            
            isTraining = true;
            const taskName = `${taskType}_${gridSize}x${gridSize}`;
            currentTrainingTask = taskName;
            
            try {
                log(`üéØ Creating persistent ${taskType} task...`);
                
                if (taskType === 'navigation') {
                    pyodide.runPython(`
import sys
from io import StringIO

old_stdout = sys.stdout
sys.stdout = captured_output = StringIO()

# Check if task already exists
task_name = "${taskName}"
if task_name not in global_persistent_ai.agents:
    grid_env = GridWorldEnvironment(width=${gridSize}, height=${gridSize})
    global_persistent_ai.add_task(task_name, grid_env)
    print(f"Created new task: {task_name}")
else:
    print(f"Continuing existing task: {task_name}")

current_env = global_persistent_ai.environments[task_name]
output = captured_output.getvalue()
sys.stdout = old_stdout
                    `);
                } else if (taskType === 'sorting') {
                    pyodide.runPython(`
import sys
from io import StringIO

old_stdout = sys.stdout
sys.stdout = captured_output = StringIO()

task_name = "${taskName}"
if task_name not in global_persistent_ai.agents:
    sorting_env = TaskEnvironment(task_type="sorting")
    global_persistent_ai.add_task(task_name, sorting_env)
    print(f"Created new task: {task_name}")
else:
    print(f"Continuing existing task: {task_name}")

current_env = global_persistent_ai.environments[task_name]
output = captured_output.getvalue()
sys.stdout = old_stdout
                    `);
                }
                
                const output = pyodide.runPython("output");
                log(output);
                
                // Show current AI state
                const currentState = pyodide.runPython(`
agent = global_persistent_ai.agents["${taskName}"]
f"Current state: {len(agent.episode_rewards)} episodes trained, exploration rate: {agent.epsilon:.3f}"
                `);
                log(`üìä ${currentState}`);
                
                updateVisualization();
                log(`üöÄ Starting persistent training for ${episodes} episodes...`);
                
                const progressContainer = document.getElementById('progress-container');
                progressContainer.style.display = 'block';
                
                await trainWithProgress(taskName, episodes);
                
                // Auto-save after training
                await savePersistentData();
                
                log('‚úÖ Training complete and saved to persistent memory!');
                document.getElementById('test-ai').disabled = false;
                document.getElementById('show-progress').disabled = false;
                document.getElementById('continue-training').disabled = false;
                
                updateMemoryStats();
                
            } catch (error) {
                log(`‚ùå Training error: ${error.message}`);
                console.error(error);
            } finally {
                isTraining = false;
                startBtn.disabled = false;
                startBtn.innerHTML = 'üöÄ Start Persistent Training';
            }
        }

        async function continueTraining() {
            if (!currentTrainingTask) {
                log('‚ùå No current task to continue!');
                return;
            }
            
            const episodes = parseInt(document.getElementById('episodes').value);
            log(`üîÑ Continuing training on ${currentTrainingTask} for ${episodes} more episodes...`);
            
            // Use same training logic but for existing task
            await startTraining();
        }

        async function trainWithProgress(taskName, episodes) {
            return new Promise((resolve, reject) => {
                let episode = 0;
                
                const trainStep = () => {
                    try {
                        const batchSize = Math.min(10, episodes - episode);
                        
                        pyodide.runPython(`
import sys
from io import StringIO

old_stdout = sys.stdout
sys.stdout = captured_output = StringIO()

# Train for ${batchSize} episodes on persistent task
agent = global_persistent_ai.agents["${taskName}"]
environment = global_persistent_ai.environments["${taskName}"]

for ep in range(${batchSize}):
    state = environment.reset()
    total_reward = 0
    steps = 0
    
    while True:
        action = agent.act(state)
        next_state, reward, done, _ = environment.step(action)
        
        agent.remember(state, action, reward, next_state, done)
        state = next_state
        total_reward += reward
        steps += 1
        
        if done or steps > 200:
            break
    
    agent.episode_rewards.append(total_reward)
    agent.episode_steps.append(steps)
    agent.replay()

# Update system stats
global_persistent_ai.system_stats['total_episodes'] += ${batchSize}

# Get recent performance
recent_rewards = agent.episode_rewards[-10:] if len(agent.episode_rewards) >= 10 else agent.episode_rewards
avg_reward = sum(recent_rewards) / len(recent_rewards) if recent_rewards else 0

output = captured_output.getvalue()
sys.stdout = old_stdout
                        `);
                        
                        episode += batchSize;
                        const progress = (episode / episodes) * 100;
                        const avgReward = pyodide.runPython("avg_reward");
                        const totalEpisodes = pyodide.runPython(`len(global_persistent_ai.agents["${taskName}"].episode_rewards)`);
                        
                        // Update progress
                        document.getElementById('progress-fill').style.width = `${progress}%`;
                        document.getElementById('progress-text').textContent = 
                            `Episode ${episode}/${episodes} (Total: ${totalEpisodes}) - Avg: ${avgReward.toFixed(2)}`;
                        
                        if (episode % 50 === 0) {
                            log(`üìä Episode ${episode}: Average reward = ${avgReward.toFixed(2)} (Total trained: ${totalEpisodes})`);
                            updateVisualization();
                        }
                        
                        if (episode < episodes) {
                            setTimeout(trainStep, 10); // Small delay for UI updates
                        } else {
                            resolve();
                        }
                        
                    } catch (error) {
                        reject(error);
                    }
                };
                
                trainStep();
            });
        }

        async function testAI() {
            if (!currentTrainingTask) {
                log('‚ùå No trained AI available!');
                return;
            }
            
            const testBtn = document.getElementById('test-ai');
            testBtn.disabled = true;
            testBtn.innerHTML = '<span class="loading"></span> Testing...';
            
            try {
                log('üéØ Testing persistent AI agent...');
                
                pyodide.runPython(`
import sys
from io import StringIO

old_stdout = sys.stdout
sys.stdout = captured_output = StringIO()

# Test the persistent agent
test_results, avg_reward = global_persistent_ai.demonstrate_task("${currentTrainingTask}", episodes=3)

output = captured_output.getvalue()
sys.stdout = old_stdout
                `);
                
                const output = pyodide.runPython("output");
                const testResults = pyodide.runPython("test_results");
                const avgReward = pyodide.runPython("avg_reward");
                
                log(output);
                log(`üèÜ Persistent AI performance: ${avgReward.toFixed(2)}`);
                
                // Show additional persistent stats
                const persistentStats = pyodide.runPython(`
agent = global_persistent_ai.agents["${currentTrainingTask}"]
{
    'total_episodes': len(agent.episode_rewards),
    'sessions': len(agent.sessions),
    'exploration_rate': agent.epsilon,
    'best_ever': max(agent.episode_rewards) if agent.episode_rewards else 0
}
                `);
                
                log(`üìà Persistent Stats:`);
                log(`   ‚Ä¢ Total episodes: ${persistentStats.get('total_episodes')}`);
                log(`   ‚Ä¢ Training sessions: ${persistentStats.get('sessions')}`);
                log(`   ‚Ä¢ Best performance: ${persistentStats.get('best_ever').toFixed(2)}`);
                log(`   ‚Ä¢ Exploration rate: ${persistentStats.get('exploration_rate').toFixed(3)}`);
                
                // Show test visualization
                if (currentTrainingTask.includes('navigation')) {
                    await visualizeTestRun(testResults);
                }
                
            } catch (error) {
                log(`‚ùå Testing error: ${error.message}`);
                console.error(error);
            } finally {
                testBtn.disabled = false;
                testBtn.innerHTML = 'üéØ Test Persistent AI';
            }
        }

        async function showProgress() {
            if (!currentTrainingTask) {
                log('‚ùå No training data available!');
                return;
            }
            
            try {
                log('üìä Analyzing persistent learning progress...');
                
                pyodide.runPython(`
progress = global_persistent_ai.get_learning_progress("${currentTrainingTask}")
                `);
                
                const progress = pyodide.runPython("progress.to_py()");
                
                log(`üìà Persistent Training Analysis:`);
                log(`   ‚Ä¢ Total episodes: ${progress.get('episodes_trained')}`);
                log(`   ‚Ä¢ Training sessions: ${progress.get('total_sessions')}`);
                log(`   ‚Ä¢ Recent avg reward: ${progress.get('recent_avg_reward').toFixed(2)}`);
                log(`   ‚Ä¢ Best reward ever: ${progress.get('best_reward').toFixed(2)}`);
                log(`   ‚Ä¢ Session avg performance: ${progress.get('avg_session_performance').toFixed(2)}`);
                log(`   ‚Ä¢ Current exploration: ${progress.get('exploration_rate').toFixed(3)}`);
                
                // Show session history
                const sessions = progress.get('sessions');
                if (sessions && sessions.length > 0) {
                    log('üìÖ Training Session History:');
                    sessions.slice(-5).forEach((session, i) => {
                        const date = new Date(session.timestamp * 1000).toLocaleDateString();
                        log(`   Session ${sessions.length - 4 + i}: ${session.episodes} episodes, avg ${session.avg_reward.toFixed(2)} (${date})`);
                    });
                }
                
                // Show learning curve
                const rewards = progress.get('all_rewards');
                if (rewards && rewards.length > 0) {
                    log('üìâ Recent learning curve (last 20 episodes):');
                    const recent = rewards.slice(-20);
                    const curve = recent.map((r, i) => `${rewards.length - 20 + i + 1}:${r.toFixed(1)}`).join(', ');
                    log(`   ${curve}`);
                }
                
            } catch (error) {
                log(`‚ùå Progress analysis error: ${error.message}`);
                console.error(error);
            }
        }

        function updateVisualization() {
            if (!currentTrainingTask) return;
            
            try {
                if (currentTrainingTask.includes('navigation')) {
                    // Get current environment state
                    pyodide.runPython(`
env = global_persistent_ai.environments["${currentTrainingTask}"]
grid_data = env.render()
agent_pos = env.agent_pos
goal_pos = env.goal_pos
walls = env.walls
                    `);
                    
                    const gridData = pyodide.runPython("grid_data");
                    const agentPos = pyodide.runPython("agent_pos");
                    const goalPos = pyodide.runPython("goal_pos");
                    const walls = pyodide.runPython("walls");
                    
                    // Show visualization
                    const viz = document.getElementById('visualization');
                    const gridDisplay = document.getElementById('grid-display');
                    const metrics = document.getElementById('metrics');
                    
                    viz.style.display = 'block';
                    
                    // Create grid HTML
                    let gridHTML = '<div class="grid-display">';
                    for (let row of gridData) {
                        gridHTML += '<div class="grid-row">';
                        for (let cell of row) {
                            let cellClass = 'empty';
                            if (cell === 'A') cellClass = 'agent';
                            else if (cell === 'G') cellClass = 'goal';
                            else if (cell === '#') cellClass = 'wall';
                            
                            gridHTML += `<div class="grid-cell ${cellClass}">${cell}</div>`;
                        }
                        gridHTML += '</div>';
                    }
                    gridHTML += '</div>';
                    
                    gridDisplay.innerHTML = gridHTML;
                    
                    // Update metrics with persistent data
                    const agent = pyodide.runPython(`
agent = global_persistent_ai.agents["${currentTrainingTask}"]
{
    'total_episodes': len(agent.episode_rewards),
    'sessions': len(agent.sessions),
    'epsilon': agent.epsilon
}
                    `);
                    
                    metrics.innerHTML = `
                        <div class="metric-row">
                            <span>Agent Position:</span>
                            <span>(${agentPos[0]}, ${agentPos[1]})</span>
                        </div>
                        <div class="metric-row">
                            <span>Goal Position:</span>
                            <span>(${goalPos[0]}, ${goalPos[1]})</span>
                        </div>
                        <div class="metric-row">
                            <span>Total Episodes:</span>
                            <span>${agent.total_episodes}</span>
                        </div>
                        <div class="metric-row">
                            <span>Training Sessions:</span>
                            <span>${agent.sessions}</span>
                        </div>
                        <div class="metric-row">
                            <span>Exploration Rate:</span>
                            <span>${agent.epsilon.toFixed(3)}</span>
                        </div>
                    `;
                }
            } catch (error) {
                console.error('Visualization error:', error);
            }
        }

        async function visualizeTestRun(testResults) {
            if (!testResults || testResults.length === 0) return;
            
            log('üé¨ Visualizing persistent AI test run...');
            
            // Show the first test episode step by step
            const episode = testResults[0];
            const states = episode.states || [];
            
            for (let i = 0; i < Math.min(states.length, 10); i++) {
                const [state, action, pos] = states[i];
                
                if (pos) {
                    // Update environment position
                    pyodide.runPython(`
env = global_persistent_ai.environments["${currentTrainingTask}"]
env.agent_pos = [${pos[0]}, ${pos[1]}]
                    `);
                    
                    updateVisualization();
                    
                    const actionNames = ['Up', 'Right', 'Down', 'Left'];
                    log(`   Step ${i + 1}: Action = ${actionNames[action] || action}, Position = (${pos[0]}, ${pos[1]})`);
                    
                    await new Promise(resolve => setTimeout(resolve, 1000));
                }
            }
            
            log('‚úÖ Persistent AI test visualization complete!');
        }

        function scrollToDemo() {
            document.getElementById('demo').scrollIntoView({ behavior: 'smooth' });
        }

        // Auto-save periodically during training
        setInterval(async () => {
            if (isTraining && currentTrainingTask) {
                await savePersistentData();
                updateMemoryStats();
            }
        }, 30000); // Auto-save every 30 seconds during training

        // Save on page unload
        window.addEventListener('beforeunload', async (event) => {
            if (currentTrainingTask) {
                await savePersistentData();
            }
        });

        // Task type change handler
        document.getElementById('task-type').addEventListener('change', function() {
            const navConfig = document.getElementById('nav-config');
            if (this.value === 'navigation') {
                navConfig.style.display = 'block';
            } else {
                navConfig.style.display = 'none';
            }
        });

        // Initialize everything when page loads
        window.addEventListener('load', function() {
            initializePyodide();
        });
    </script>
</body>
</html>
